{"cells":[{"cell_type":"markdown","metadata":{"id":"0MqwxPoaSq_G"},"source":["Week 11: Day 4 â€“ What is Text Classification in NLP"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b2TBsW9iSq_N"},"outputs":[],"source":["# Import library\n","import pandas as pd\n","import numpy as np\n","import nltk\n","from nltk import word_tokenize"]},{"cell_type":"markdown","metadata":{"id":"5_cZdxoFSq_P"},"source":["### The Bag of words Approach\n","In common terms, it basically creates a list of all the unique words present across all the documents and then count the frequency of each of these words appearing in the documents"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u81zXxC5Sq_P"},"outputs":[],"source":["review_1 = 'The movie was good and we really like it'\n","review_2 = 'the movie was good but the ending was boring'\n","review_3 ='we did not like the movie as it was too lenghty'"]},{"cell_type":"markdown","metadata":{"id":"2nV1N7JPSq_Q"},"source":["We'll now join all the three reviews by creating a set to get all the unique words across all the reviews:\n","\n","- The goal is to classify the movie reviews into positive or negative"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"So-6Y0dMSq_R","outputId":"48c5d9f6-1147-4ca9-b811-3c036252018a"},"outputs":[{"name":"stdout","output_type":"stream","text":["['The', 'movie', 'was', 'good', 'and', 'we', 'really', 'like', 'it']\n","['the', 'movie', 'was', 'good', 'but', 'the', 'ending', 'was', 'boring']\n","['we', 'did', 'not', 'like', 'the', 'movie', 'as', 'it', 'was', 'too', 'lenghty']\n"]}],"source":["# convert all the words to tokens\n","review_1_tokens = word_tokenize(review_1)\n","print(review_1_tokens)\n","review_2_tokens = word_tokenize(review_2)\n","print(review_2_tokens)\n","review_3_tokens = word_tokenize(review_3)\n","print(review_3_tokens)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fwIXThenSq_S","outputId":"9239f3ee-1771-4ee5-9dfd-43b1feb45cba"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'boring', 'ending', 'movie', 'and', 'we', 'but', 'The', 'the', 'lenghty', 'it', 'as', 'too', 'was', 'not', 'did', 'good', 'really', 'like'}\n"]}],"source":["# Union of tokenized words\n","review_tokens = set(review_1_tokens).union(set(review_2_tokens)).union(set(review_3_tokens))\n","print(review_tokens)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DB1Xz9ZkSq_T","outputId":"85acee54-a29c-4c35-faff-6cf413914846"},"outputs":[{"data":{"text/plain":["18"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# number of words\n","len(review_tokens)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WYTXNKHRSq_U","outputId":"3c220c59-fe0d-45d6-d8a4-b0c6071029be"},"outputs":[{"data":{"text/plain":["{'The',\n"," 'and',\n"," 'as',\n"," 'boring',\n"," 'but',\n"," 'did',\n"," 'ending',\n"," 'good',\n"," 'it',\n"," 'lenghty',\n"," 'like',\n"," 'movie',\n"," 'not',\n"," 'really',\n"," 'the',\n"," 'too',\n"," 'was',\n"," 'we'}"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["review_tokens"]},{"cell_type":"markdown","metadata":{"id":"I7-JCyOkSq_W"},"source":["### Processing Tokens\n","\n","we'll now create a dictionary where the keys will be the 18 tokens and the default value of each token will be 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VjstgCoQSq_Y"},"outputs":[],"source":["review1_dict = dict.fromkeys(review_tokens,0)\n","review2_dict = dict.fromkeys(review_tokens,0)\n","review3_dict = dict.fromkeys(review_tokens,0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AQD98kScSq_c"},"outputs":[],"source":["for token in review_1_tokens:\n","    review1_dict[token]+=1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"owlNb_ToSq_e","outputId":"2b623fb0-2c85-4219-e24f-10273499c9e8"},"outputs":[{"data":{"text/plain":["{'boring': 0,\n"," 'ending': 0,\n"," 'movie': 1,\n"," 'and': 1,\n"," 'we': 1,\n"," 'but': 0,\n"," 'The': 1,\n"," 'the': 0,\n"," 'lenghty': 0,\n"," 'it': 1,\n"," 'as': 0,\n"," 'too': 0,\n"," 'was': 1,\n"," 'not': 0,\n"," 'did': 0,\n"," 'good': 1,\n"," 'really': 1,\n"," 'like': 1}"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["review1_dict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nN-yzJJBSq_f"},"outputs":[],"source":["for token in review_2_tokens:\n","    review2_dict[token]+=1\n","    \n","for token in review_3_tokens:\n","    review3_dict[token]+=1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tLIFd4ooSq_g"},"outputs":[],"source":["# convert to a data frame\n","reviews_Dict_DF = pd.DataFrame([review1_dict,review2_dict,review3_dict])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DjBDEKB1Sq_i","outputId":"d04c9b31-84ab-4e98-813b-681235cece64"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>boring</th>\n","      <th>ending</th>\n","      <th>movie</th>\n","      <th>and</th>\n","      <th>we</th>\n","      <th>but</th>\n","      <th>The</th>\n","      <th>the</th>\n","      <th>lenghty</th>\n","      <th>it</th>\n","      <th>as</th>\n","      <th>too</th>\n","      <th>was</th>\n","      <th>not</th>\n","      <th>did</th>\n","      <th>good</th>\n","      <th>really</th>\n","      <th>like</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   boring  ending  movie  and  we  but  The  the  lenghty  it  as  too  was  \\\n","0       0       0      1    1   1    0    1    0        0   1   0    0    1   \n","1       1       1      1    0   0    1    0    2        0   0   0    0    2   \n","2       0       0      1    0   1    0    0    1        1   1   1    1    1   \n","\n","   not  did  good  really  like  \n","0    0    0     1       1     1  \n","1    0    0     1       0     0  \n","2    1    1     0       0     1  "]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["reviews_Dict_DF\n","# at this state it is easy to impelement any machine learning algorithim"]},{"cell_type":"markdown","metadata":{"id":"DoctWhrQSq_j"},"source":["<!-- ## Adding Counts To The Tokens\n","Create a for loop which for each of the tokens in the review will add 1 to the value of that token in the dictionary:\n","     -->"]},{"cell_type":"markdown","metadata":{"id":"UBCY3L0tSq_j"},"source":["## Count Vectorization in Scikit-Learn\n","\n","Let's start by importing the necessary libraries as shown below:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IN4lKHEaSq_k"},"outputs":[],"source":["from sklearn.feature_extraction.text import CountVectorizer"]},{"cell_type":"markdown","metadata":{"id":"Y2dMMxGmSq_l"},"source":["Using the same review, create a list of same reviews:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Q21DtX_Sq_l","outputId":"9bb56f50-c0b2-4e17-ec06-900614324403"},"outputs":[{"data":{"text/plain":["['The movie was good and we really like it',\n"," 'the movie was good but the ending was boring',\n"," 'we did not like the movie as it was too lenghty']"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["review_list = [review_1,review_2,review_3]\n","review_list"]},{"cell_type":"markdown","metadata":{"id":"PtDXl0ztSq_m"},"source":["Now, instantiate the count vectorizer and fit transform it with the list:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"veT-a8OzSq_n","outputId":"ac5cde5a-09a6-4adb-9758-9952f5d201cb"},"outputs":[{"data":{"text/plain":["CountVectorizer()"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["count_vect = CountVectorizer()\n","count_vect"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"28HW2BYpSq_o","outputId":"127e3897-8fa1-4e32-edaa-2d1fac730aba"},"outputs":[{"data":{"text/plain":["array([[1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1],\n","       [0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 2, 0, 2, 0],\n","       [0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]], dtype=int64)"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["X_counts = count_vect.fit_transform(review_list)\n","X_counts.toarray()"]},{"cell_type":"markdown","metadata":{"id":"xdw0QAprSq_p"},"source":["Let's check the type of count vectorized matrix:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2CIoXqJ9Sq_q","outputId":"a4a20e04-d6bc-4975-b300-b35fa1c035cf"},"outputs":[{"data":{"text/plain":["scipy.sparse.csr.csr_matrix"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["type(X_counts)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eNqLAivcSq_r","outputId":"4b4a6425-fe6d-4890-ac0d-7fb8953f2d45"},"outputs":[{"data":{"text/plain":["['and',\n"," 'as',\n"," 'boring',\n"," 'but',\n"," 'did',\n"," 'ending',\n"," 'good',\n"," 'it',\n"," 'lenghty',\n"," 'like',\n"," 'movie',\n"," 'not',\n"," 'really',\n"," 'the',\n"," 'too',\n"," 'was',\n"," 'we']"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["# returns the list of unique nnames as a result of count vectorization:  \n","X_names = count_vect.get_feature_names()\n","X_names"]},{"cell_type":"markdown","metadata":{"id":"Izyj6maBSq_r"},"source":["## Working On the vectorizer Matrix\n","\n","You will now create a new pandas datafeame out of the scipy csr matrix and the vectorizer as datafeame column names:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W89w-lXuSq_s","outputId":"c65ebbe3-d4dc-4b55-a31d-34264bb303fa"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>and</th>\n","      <th>as</th>\n","      <th>boring</th>\n","      <th>but</th>\n","      <th>did</th>\n","      <th>ending</th>\n","      <th>good</th>\n","      <th>it</th>\n","      <th>lenghty</th>\n","      <th>like</th>\n","      <th>movie</th>\n","      <th>not</th>\n","      <th>really</th>\n","      <th>the</th>\n","      <th>too</th>\n","      <th>was</th>\n","      <th>we</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   and  as  boring  but  did  ending  good  it  lenghty  like  movie  not  \\\n","0    1   0       0    0    0       0     1   1        0     1      1    0   \n","1    0   0       1    1    0       1     1   0        0     0      1    0   \n","2    0   1       0    0    1       0     0   1        1     1      1    1   \n","\n","   really  the  too  was  we  \n","0       1    1    0    1   1  \n","1       0    2    0    2   0  \n","2       0    1    1    1   1  "]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["# Convert to a dataframe and array\n","a=pd.DataFrame(X_counts.toarray(),columns=X_names)\n","a\n","# Note that Count Vectorizer omits words that are less than 2 letters long"]},{"cell_type":"markdown","metadata":{"jupyter":{"outputs_hidden":true},"id":"Oo9VZ1vBSq_t"},"source":["conda install -c anaconda ipython"]},{"cell_type":"markdown","metadata":{"jupyter":{"outputs_hidden":true},"id":"kqUni_8CSq_u"},"source":["!pip install sklearn\n","import sklearn"]},{"cell_type":"markdown","metadata":{"jupyter":{"outputs_hidden":true},"id":"5wCwWmesSq_u"},"source":["import sys\n","print(sys.path)"]},{"cell_type":"markdown","metadata":{"id":"09Aij5sUSq_v"},"source":["## TF -IDF in Scikit-Learn\n","A statistics which shows, how important a word is in a collection of document\n","\n","TF(t,d): The total number of occurences of word t in the instances of document d\n","\n","IDF: log(total number of documents/number of documents containing t)\n","\n","TF_IDF Score: TFIDF(d,t) = TF(d,t)*IDF(t)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FuN9EcmbSq_v"},"outputs":[],"source":["# Let us start with importing the library for TF-IDF:\n","from sklearn.feature_extraction.text import TfidfVectorizer\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GNU0398RSq_w","outputId":"329bc371-653b-4a54-df1c-2562862c3dcd"},"outputs":[{"data":{"text/plain":["'0.23.2'"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["import sklearn\n","sklearn.__version__"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YvF4XjWSSq_x"},"outputs":[],"source":["# Instantiate the TF IDF vectorizer by passing the parameters:\n","tf_vect =TfidfVectorizer(min_df=1,# Tells the vectorizer to ignore the words that have a document frequency less than this number\n","                         lowercase=True, # Boolean parameter to convert all the words into lowercase before tokenizing\n","                         stop_words='english')"]},{"cell_type":"markdown","metadata":{"id":"cyAmM-ENSq_x"},"source":["Once we have instantiated the vectorizer, we can pass the review list of all the three reviews to the same:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hrpf9UGDSq_y"},"outputs":[],"source":["# fit and transform data into matrix\n","tf_matrix = tf_vect.fit_transform(review_list)"]},{"cell_type":"markdown","metadata":{"id":"x38E4nouSq_y"},"source":["The above will result into a scipy csr matrix with 3 rows and 8 columns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OE111zyUSq_z","outputId":"65d30559-61d5-477d-9d0d-99170975b760"},"outputs":[{"data":{"text/plain":["scipy.sparse.csr.csr_matrix"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["type(tf_matrix)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VeNu5CXlSq_0","outputId":"a8b02ba3-19e6-46fd-c694-8ea15f4fa47b"},"outputs":[{"data":{"text/plain":["(3, 8)"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["# returns row and columns\n","tf_matrix.shape"]},{"cell_type":"markdown","metadata":{"id":"lrguh-aTSq_0"},"source":["You can check the names that the vectorizer has counted by:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2XYpqWvkSq_1"},"outputs":[],"source":["# you get back a list with 8 tokens\n","tf_names = tf_vect.get_feature_names()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tmn9Z445Sq_2","outputId":"13360b52-ae83-4f55-acd8-c5a0a204c3ab"},"outputs":[{"data":{"text/plain":["['boring', 'did', 'ending', 'good', 'lenghty', 'like', 'movie', 'really']"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["tf_names"]},{"cell_type":"markdown","metadata":{"id":"Tu8nDVFVSq_2"},"source":["## CSR Matrix To Pandas DF\n"," You can now create a pandas dataframe by passing a scipy csr matrix as values and the list of tokens, you got above as column names:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WMjKki7nSq_3"},"outputs":[],"source":["# The dataframe has tf-idf values for all the 8 tokens in floats across all the three reviews\n","tf_df = pd.DataFrame(tf_matrix.toarray(),columns=tf_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MnVbLYTTSq_3","outputId":"672c2f39-1494-4ebb-ee92-ead6d29b3bda"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>boring</th>\n","      <th>did</th>\n","      <th>ending</th>\n","      <th>good</th>\n","      <th>lenghty</th>\n","      <th>like</th>\n","      <th>movie</th>\n","      <th>really</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.480458</td>\n","      <td>0.000000</td>\n","      <td>0.480458</td>\n","      <td>0.373119</td>\n","      <td>0.631745</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.584483</td>\n","      <td>0.000000</td>\n","      <td>0.584483</td>\n","      <td>0.444514</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.345205</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.000000</td>\n","      <td>0.584483</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.584483</td>\n","      <td>0.444514</td>\n","      <td>0.345205</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     boring       did    ending      good   lenghty      like     movie  \\\n","0  0.000000  0.000000  0.000000  0.480458  0.000000  0.480458  0.373119   \n","1  0.584483  0.000000  0.584483  0.444514  0.000000  0.000000  0.345205   \n","2  0.000000  0.584483  0.000000  0.000000  0.584483  0.444514  0.345205   \n","\n","     really  \n","0  0.631745  \n","1  0.000000  \n","2  0.000000  "]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["# probability of the word occuring\n","tf_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qc2JeBqaSq_4"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}