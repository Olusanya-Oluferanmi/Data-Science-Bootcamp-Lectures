{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOP6jWdikcEkXn97AxIJgEf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"741af783"},"source":["Week 11: Day 5 - PySpark With Python-GroupBy And Aggregate Functions"]},{"cell_type":"markdown","metadata":{"id":"439f816a"},"source":["# Pyspark groupby and aggregate functions"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":321},"id":"194828ec","executionInfo":{"status":"error","timestamp":1663068278080,"user_tz":420,"elapsed":49,"user":{"displayName":"Favour Olusanya","userId":"07663144389054108267"}},"outputId":"ab611448-e0c7-4ee7-d44b-e97b7fe02b79"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-1f156700e368>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import spark session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["# Import spark session\n","from pyspark.sql import SparkSession"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2e9acef9"},"outputs":[],"source":["# spark variable to complete the spark session\n","spark=SparkSession.builder.appName('Agg').getOrCreate()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dabed2cb"},"outputs":[],"source":["spark"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a40b54f6"},"outputs":[],"source":["df_pyspark=spark.read.csv('test3.csv', header=True,inferSchema=True)\n","df_pyspark.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"50172481"},"outputs":[],"source":["# Print datatype of the columns\n","df_pyspark.printSchema()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d94b88a1"},"outputs":[],"source":["#group by\n","# group to find the maximum salary\n","df_pyspark.groupBy('Name').sum().show() "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"da61e37d"},"outputs":[],"source":["# group by name find the maximum salary\n","df_pyspark.groupBy('Name').max().show() "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"49a318a6"},"outputs":[],"source":["# group by name find the minimum salary\n","df_pyspark.groupBy('Name').min().show() "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ce3d799b"},"outputs":[],"source":["# group by name find the average salary\n","df_pyspark.groupBy('Name').avg().show() "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b72dc59b"},"outputs":[],"source":["# groupby department which gives maximum salary\n","df_pyspark.groupBy('Departments').sum().show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8c375eb4"},"outputs":[],"source":["# groupby mean of salary in each department\n","df_pyspark.groupBy('Departments').mean().show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ec5435da"},"outputs":[],"source":["# count in each department\n","df_pyspark.groupBy('Departments').count().show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c3add922"},"outputs":[],"source":["df_pyspark.agg({'Salary': 'sum'}).show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e01e6de2"},"outputs":[],"source":["df_pyspark.agg"]}]}