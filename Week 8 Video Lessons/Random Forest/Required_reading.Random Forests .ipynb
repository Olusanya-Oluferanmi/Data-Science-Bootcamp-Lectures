{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "413b91e7-7b0b-42d7-9eba-1b585d699043",
   "metadata": {},
   "source": [
    "#### Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da26e02-0643-46db-baa3-21758a1dfe1e",
   "metadata": {},
   "source": [
    "Random Forest is a type of Ensemble Model.\n",
    "An Ensemble model is a combination of Several weak learners to form a strong learner. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2206294-342d-4f91-a6ca-79a4b4261d84",
   "metadata": {},
   "source": [
    "Random Forests are extensions of Decision Trees whereby several trees are grown to form a Forest.\n",
    "Though Random Forest are made of several Decision Trees,each Decision Tree is trained on a subset of data that is randomly selected hence the name Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2d60c9-dc0e-47a5-b526-f9164309e218",
   "metadata": {},
   "source": [
    "The other trick of random forest is that\n",
    "unlike a decision tree where the best attribute is chosen in order to split\n",
    "samples at a decision node from all available attributes, random forest only\n",
    "picks the best attribute from a subset of randomly chosen attributes for each\n",
    "decision node.\n",
    "Due to this,each time we run the algorithm, we are likely to end up with different tree structures;each node in a tree is not deterministic.But, themost informative attributes still find their way to trees in the forestand are present across many trees.\n",
    "This makes the\n",
    "results of the random forest algorithm to be less prone to errors due to\n",
    "variations in the input data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcab9079-fee9-4433-8fe4-7bf0ee473422",
   "metadata": {},
   "source": [
    "The subset of data on which a decision tree that makes up a random forest is\n",
    "trained on is called bagged data and is usually around 60% of the entire\n",
    "dataset. The remainder on which the performance of individuals trees are\n",
    "tested on is known as the out-of-bag data.The Randomization process- each tree in the Forest is trained and evaluated ona differentsubset of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf771b7-51f9-46bd-b005-95de31738e96",
   "metadata": {},
   "source": [
    "We would now try out a random forest classifier on the wine dataset and\n",
    "compare its performance on the test set to the decision tree model in the\n",
    "previous section. The beautiful thing about using machine learning models\n",
    "from Scikit-Learn is that the APIs to train and test a model are the same\n",
    "regardless of the algorithm being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "707f8f98-a5d7-4580-b526-98bdf8ad27d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary library\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a32a8054-aa04-4fe0-8f4f-d38298962976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataset = pd.read_csv(\"C:\\\\Users\\\\User\\\\Desktop\\\\Datasetnexustech\\\\Data Science Boot_Camp\\\\Lecture sessions\\\\wine.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f88070-1711-4035-ba72-7382da0bddd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wine</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic.acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Acl</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid.phenols</th>\n",
       "      <th>Proanth</th>\n",
       "      <th>Color.int</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>3</td>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>3</td>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>3</td>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>3</td>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>3</td>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Wine  Alcohol  Malic.acid   Ash   Acl   Mg  Phenols  Flavanoids  \\\n",
       "0       1    14.23        1.71  2.43  15.6  127     2.80        3.06   \n",
       "1       1    13.20        1.78  2.14  11.2  100     2.65        2.76   \n",
       "2       1    13.16        2.36  2.67  18.6  101     2.80        3.24   \n",
       "3       1    14.37        1.95  2.50  16.8  113     3.85        3.49   \n",
       "4       1    13.24        2.59  2.87  21.0  118     2.80        2.69   \n",
       "..    ...      ...         ...   ...   ...  ...      ...         ...   \n",
       "173     3    13.71        5.65  2.45  20.5   95     1.68        0.61   \n",
       "174     3    13.40        3.91  2.48  23.0  102     1.80        0.75   \n",
       "175     3    13.27        4.28  2.26  20.0  120     1.59        0.69   \n",
       "176     3    13.17        2.59  2.37  20.0  120     1.65        0.68   \n",
       "177     3    14.13        4.10  2.74  24.5   96     2.05        0.76   \n",
       "\n",
       "     Nonflavanoid.phenols  Proanth  Color.int   Hue    OD  Proline  \n",
       "0                    0.28     2.29       5.64  1.04  3.92     1065  \n",
       "1                    0.26     1.28       4.38  1.05  3.40     1050  \n",
       "2                    0.30     2.81       5.68  1.03  3.17     1185  \n",
       "3                    0.24     2.18       7.80  0.86  3.45     1480  \n",
       "4                    0.39     1.82       4.32  1.04  2.93      735  \n",
       "..                    ...      ...        ...   ...   ...      ...  \n",
       "173                  0.52     1.06       7.70  0.64  1.74      740  \n",
       "174                  0.43     1.41       7.30  0.70  1.56      750  \n",
       "175                  0.43     1.35      10.20  0.59  1.56      835  \n",
       "176                  0.53     1.46       9.30  0.60  1.62      840  \n",
       "177                  0.56     1.35       9.20  0.61  1.60      560  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe9f0e75-e587-45db-ad74-bf76bc5cc1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate features and labels\n",
    "features = dataset.drop(['Wine'], axis=1)\n",
    "labels = dataset['Wine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e64af4a-2d34-4b07-8734-12bcc859a327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4e4343f-5a9f-435c-923a-581d804e5e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random forest classifier from sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9ba0a27-7f5c-4f76-812e-2001ec3dd558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit classifier on data\n",
    "classifier.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3aa6541-71b6-449f-814b-3e9db36db03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict classes of test set samples\n",
    "pred = classifier.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13f86b66-4e43-421f-aee2-765bc5ca963f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "# evaluate classifier performance using accuracy metric\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(labels_test, pred)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d935d331-19ed-42ab-82aa-56ec3feeb4cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
