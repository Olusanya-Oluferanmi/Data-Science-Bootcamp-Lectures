{"cells":[{"cell_type":"markdown","metadata":{"id":"FAw-Furp8Djw"},"source":["- # ENSEMBLE LEARNING"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8gXjSRLB8Dj4"},"outputs":[],"source":["# Importing the necessary libraries\n","import pandas as pd\n","from sklearn import model_selection\n","from sklearn.ensemble import AdaBoostClassifier"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2I4zzSBI8Dj9"},"outputs":[],"source":["#import and loading the dataset\n","dataframe = pd.read_csv('C:\\\\Users\\\\Feranmi\\\\Downloads\\\\diabetes.csv')\n","array = dataframe.values\n","# seperating the data into independent and dependent variable\n","X = array[:, 0:8]\n","Y = array[:, 8]\n","seed = 7\n","num_tress= 30"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GR1TygdR8DkA"},"outputs":[],"source":["# This is to hide warnings in python\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WPxPXmNA8DkC","outputId":"a143a615-837a-4793-8db5-8de72dfc95c1"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.760457963089542\n"]}],"source":["# Number of split group\n","# model used\n","kfold = model_selection.KFold(n_splits=10, random_state=seed)\n","model = AdaBoostClassifier(n_estimators=num_tress, random_state=seed)\n","results = model_selection.cross_val_score(model,X,Y,cv=kfold)\n","print(results.mean())# mean of the data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M1YyaAri8DkG","outputId":"340f66b3-39d3-4bf1-f617-092c8fd6af94"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: xgboost in c:\\users\\feranmi\\anaconda3\\lib\\site-packages (1.5.2)\n","Requirement already satisfied: scipy in c:\\users\\feranmi\\anaconda3\\lib\\site-packages (from xgboost) (1.5.2)\n","Requirement already satisfied: numpy in c:\\users\\feranmi\\anaconda3\\lib\\site-packages (from xgboost) (1.19.2)\n"]}],"source":["# to install xgboost\n","!pip install xgboost  "]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"Bvkmm_YZ8DkJ","outputId":"af270c61-facb-4476-9f92-14f1ff28ab6a"},"outputs":[{"name":"stdout","output_type":"stream","text":["[13:22:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[13:22:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[13:22:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[13:22:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[13:22:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[13:22:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[13:22:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[13:22:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[13:22:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[13:22:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","0.7499487354750513\n"]}],"source":["# importing neccesary packages\n","from sklearn import svm\n","#SVM-> Support vector machines \n","from xgboost import XGBClassifier\n","#XGBoost-> Extreme Gradient Boosting\n","clf = XGBClassifier()\n","\n","seed = 7\n","num_trees=30\n","kfold = model_selection.KFold(n_splits= 10,random_state=seed)\n","model = XGBClassifier(n_estimators=num_trees, random_state=seed)\n","results = model_selection.cross_val_score(model,X,Y,cv=kfold)\n","print(results.mean())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T1wztZ3C8DkM"},"outputs":[],"source":["from sklearn.datasets import load_iris # iris is a dummy dataset in python"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ApEfa0Qi8DkP","outputId":"c4cf3730-4f77-4dff-fd7e-8adee2bd3919"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'data': array([[5.1, 3.5, 1.4, 0.2],\n","       [4.9, 3. , 1.4, 0.2],\n","       [4.7, 3.2, 1.3, 0.2],\n","       [4.6, 3.1, 1.5, 0.2],\n","       [5. , 3.6, 1.4, 0.2],\n","       [5.4, 3.9, 1.7, 0.4],\n","       [4.6, 3.4, 1.4, 0.3],\n","       [5. , 3.4, 1.5, 0.2],\n","       [4.4, 2.9, 1.4, 0.2],\n","       [4.9, 3.1, 1.5, 0.1],\n","       [5.4, 3.7, 1.5, 0.2],\n","       [4.8, 3.4, 1.6, 0.2],\n","       [4.8, 3. , 1.4, 0.1],\n","       [4.3, 3. , 1.1, 0.1],\n","       [5.8, 4. , 1.2, 0.2],\n","       [5.7, 4.4, 1.5, 0.4],\n","       [5.4, 3.9, 1.3, 0.4],\n","       [5.1, 3.5, 1.4, 0.3],\n","       [5.7, 3.8, 1.7, 0.3],\n","       [5.1, 3.8, 1.5, 0.3],\n","       [5.4, 3.4, 1.7, 0.2],\n","       [5.1, 3.7, 1.5, 0.4],\n","       [4.6, 3.6, 1. , 0.2],\n","       [5.1, 3.3, 1.7, 0.5],\n","       [4.8, 3.4, 1.9, 0.2],\n","       [5. , 3. , 1.6, 0.2],\n","       [5. , 3.4, 1.6, 0.4],\n","       [5.2, 3.5, 1.5, 0.2],\n","       [5.2, 3.4, 1.4, 0.2],\n","       [4.7, 3.2, 1.6, 0.2],\n","       [4.8, 3.1, 1.6, 0.2],\n","       [5.4, 3.4, 1.5, 0.4],\n","       [5.2, 4.1, 1.5, 0.1],\n","       [5.5, 4.2, 1.4, 0.2],\n","       [4.9, 3.1, 1.5, 0.2],\n","       [5. , 3.2, 1.2, 0.2],\n","       [5.5, 3.5, 1.3, 0.2],\n","       [4.9, 3.6, 1.4, 0.1],\n","       [4.4, 3. , 1.3, 0.2],\n","       [5.1, 3.4, 1.5, 0.2],\n","       [5. , 3.5, 1.3, 0.3],\n","       [4.5, 2.3, 1.3, 0.3],\n","       [4.4, 3.2, 1.3, 0.2],\n","       [5. , 3.5, 1.6, 0.6],\n","       [5.1, 3.8, 1.9, 0.4],\n","       [4.8, 3. , 1.4, 0.3],\n","       [5.1, 3.8, 1.6, 0.2],\n","       [4.6, 3.2, 1.4, 0.2],\n","       [5.3, 3.7, 1.5, 0.2],\n","       [5. , 3.3, 1.4, 0.2],\n","       [7. , 3.2, 4.7, 1.4],\n","       [6.4, 3.2, 4.5, 1.5],\n","       [6.9, 3.1, 4.9, 1.5],\n","       [5.5, 2.3, 4. , 1.3],\n","       [6.5, 2.8, 4.6, 1.5],\n","       [5.7, 2.8, 4.5, 1.3],\n","       [6.3, 3.3, 4.7, 1.6],\n","       [4.9, 2.4, 3.3, 1. ],\n","       [6.6, 2.9, 4.6, 1.3],\n","       [5.2, 2.7, 3.9, 1.4],\n","       [5. , 2. , 3.5, 1. ],\n","       [5.9, 3. , 4.2, 1.5],\n","       [6. , 2.2, 4. , 1. ],\n","       [6.1, 2.9, 4.7, 1.4],\n","       [5.6, 2.9, 3.6, 1.3],\n","       [6.7, 3.1, 4.4, 1.4],\n","       [5.6, 3. , 4.5, 1.5],\n","       [5.8, 2.7, 4.1, 1. ],\n","       [6.2, 2.2, 4.5, 1.5],\n","       [5.6, 2.5, 3.9, 1.1],\n","       [5.9, 3.2, 4.8, 1.8],\n","       [6.1, 2.8, 4. , 1.3],\n","       [6.3, 2.5, 4.9, 1.5],\n","       [6.1, 2.8, 4.7, 1.2],\n","       [6.4, 2.9, 4.3, 1.3],\n","       [6.6, 3. , 4.4, 1.4],\n","       [6.8, 2.8, 4.8, 1.4],\n","       [6.7, 3. , 5. , 1.7],\n","       [6. , 2.9, 4.5, 1.5],\n","       [5.7, 2.6, 3.5, 1. ],\n","       [5.5, 2.4, 3.8, 1.1],\n","       [5.5, 2.4, 3.7, 1. ],\n","       [5.8, 2.7, 3.9, 1.2],\n","       [6. , 2.7, 5.1, 1.6],\n","       [5.4, 3. , 4.5, 1.5],\n","       [6. , 3.4, 4.5, 1.6],\n","       [6.7, 3.1, 4.7, 1.5],\n","       [6.3, 2.3, 4.4, 1.3],\n","       [5.6, 3. , 4.1, 1.3],\n","       [5.5, 2.5, 4. , 1.3],\n","       [5.5, 2.6, 4.4, 1.2],\n","       [6.1, 3. , 4.6, 1.4],\n","       [5.8, 2.6, 4. , 1.2],\n","       [5. , 2.3, 3.3, 1. ],\n","       [5.6, 2.7, 4.2, 1.3],\n","       [5.7, 3. , 4.2, 1.2],\n","       [5.7, 2.9, 4.2, 1.3],\n","       [6.2, 2.9, 4.3, 1.3],\n","       [5.1, 2.5, 3. , 1.1],\n","       [5.7, 2.8, 4.1, 1.3],\n","       [6.3, 3.3, 6. , 2.5],\n","       [5.8, 2.7, 5.1, 1.9],\n","       [7.1, 3. , 5.9, 2.1],\n","       [6.3, 2.9, 5.6, 1.8],\n","       [6.5, 3. , 5.8, 2.2],\n","       [7.6, 3. , 6.6, 2.1],\n","       [4.9, 2.5, 4.5, 1.7],\n","       [7.3, 2.9, 6.3, 1.8],\n","       [6.7, 2.5, 5.8, 1.8],\n","       [7.2, 3.6, 6.1, 2.5],\n","       [6.5, 3.2, 5.1, 2. ],\n","       [6.4, 2.7, 5.3, 1.9],\n","       [6.8, 3. , 5.5, 2.1],\n","       [5.7, 2.5, 5. , 2. ],\n","       [5.8, 2.8, 5.1, 2.4],\n","       [6.4, 3.2, 5.3, 2.3],\n","       [6.5, 3. , 5.5, 1.8],\n","       [7.7, 3.8, 6.7, 2.2],\n","       [7.7, 2.6, 6.9, 2.3],\n","       [6. , 2.2, 5. , 1.5],\n","       [6.9, 3.2, 5.7, 2.3],\n","       [5.6, 2.8, 4.9, 2. ],\n","       [7.7, 2.8, 6.7, 2. ],\n","       [6.3, 2.7, 4.9, 1.8],\n","       [6.7, 3.3, 5.7, 2.1],\n","       [7.2, 3.2, 6. , 1.8],\n","       [6.2, 2.8, 4.8, 1.8],\n","       [6.1, 3. , 4.9, 1.8],\n","       [6.4, 2.8, 5.6, 2.1],\n","       [7.2, 3. , 5.8, 1.6],\n","       [7.4, 2.8, 6.1, 1.9],\n","       [7.9, 3.8, 6.4, 2. ],\n","       [6.4, 2.8, 5.6, 2.2],\n","       [6.3, 2.8, 5.1, 1.5],\n","       [6.1, 2.6, 5.6, 1.4],\n","       [7.7, 3. , 6.1, 2.3],\n","       [6.3, 3.4, 5.6, 2.4],\n","       [6.4, 3.1, 5.5, 1.8],\n","       [6. , 3. , 4.8, 1.8],\n","       [6.9, 3.1, 5.4, 2.1],\n","       [6.7, 3.1, 5.6, 2.4],\n","       [6.9, 3.1, 5.1, 2.3],\n","       [5.8, 2.7, 5.1, 1.9],\n","       [6.8, 3.2, 5.9, 2.3],\n","       [6.7, 3.3, 5.7, 2.5],\n","       [6.7, 3. , 5.2, 2.3],\n","       [6.3, 2.5, 5. , 1.9],\n","       [6.5, 3. , 5.2, 2. ],\n","       [6.2, 3.4, 5.4, 2.3],\n","       [5.9, 3. , 5.1, 1.8]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n","       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n","       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), 'frame': None, 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'), 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...', 'feature_names': ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'], 'filename': 'C:\\\\Users\\\\Feranmi\\\\Anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\iris.csv'}\n"]}],"source":["# Load dataset\n","iris_data = load_iris()\n","print(iris_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e0Fro7Pe8DkS"},"outputs":[],"source":["data_input =iris_data.data\n","data_output = iris_data.target"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1YJz3cov8DkV","outputId":"990f2c7a-80ff-45f7-c90e-5261a546f9ce"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[5.1 3.5 1.4 0.2]\n"," [4.9 3.  1.4 0.2]\n"," [4.7 3.2 1.3 0.2]\n"," [4.6 3.1 1.5 0.2]\n"," [5.  3.6 1.4 0.2]\n"," [5.4 3.9 1.7 0.4]\n"," [4.6 3.4 1.4 0.3]\n"," [5.  3.4 1.5 0.2]\n"," [4.4 2.9 1.4 0.2]\n"," [4.9 3.1 1.5 0.1]\n"," [5.4 3.7 1.5 0.2]\n"," [4.8 3.4 1.6 0.2]\n"," [4.8 3.  1.4 0.1]\n"," [4.3 3.  1.1 0.1]\n"," [5.8 4.  1.2 0.2]\n"," [5.7 4.4 1.5 0.4]\n"," [5.4 3.9 1.3 0.4]\n"," [5.1 3.5 1.4 0.3]\n"," [5.7 3.8 1.7 0.3]\n"," [5.1 3.8 1.5 0.3]\n"," [5.4 3.4 1.7 0.2]\n"," [5.1 3.7 1.5 0.4]\n"," [4.6 3.6 1.  0.2]\n"," [5.1 3.3 1.7 0.5]\n"," [4.8 3.4 1.9 0.2]\n"," [5.  3.  1.6 0.2]\n"," [5.  3.4 1.6 0.4]\n"," [5.2 3.5 1.5 0.2]\n"," [5.2 3.4 1.4 0.2]\n"," [4.7 3.2 1.6 0.2]\n"," [4.8 3.1 1.6 0.2]\n"," [5.4 3.4 1.5 0.4]\n"," [5.2 4.1 1.5 0.1]\n"," [5.5 4.2 1.4 0.2]\n"," [4.9 3.1 1.5 0.2]\n"," [5.  3.2 1.2 0.2]\n"," [5.5 3.5 1.3 0.2]\n"," [4.9 3.6 1.4 0.1]\n"," [4.4 3.  1.3 0.2]\n"," [5.1 3.4 1.5 0.2]\n"," [5.  3.5 1.3 0.3]\n"," [4.5 2.3 1.3 0.3]\n"," [4.4 3.2 1.3 0.2]\n"," [5.  3.5 1.6 0.6]\n"," [5.1 3.8 1.9 0.4]\n"," [4.8 3.  1.4 0.3]\n"," [5.1 3.8 1.6 0.2]\n"," [4.6 3.2 1.4 0.2]\n"," [5.3 3.7 1.5 0.2]\n"," [5.  3.3 1.4 0.2]\n"," [7.  3.2 4.7 1.4]\n"," [6.4 3.2 4.5 1.5]\n"," [6.9 3.1 4.9 1.5]\n"," [5.5 2.3 4.  1.3]\n"," [6.5 2.8 4.6 1.5]\n"," [5.7 2.8 4.5 1.3]\n"," [6.3 3.3 4.7 1.6]\n"," [4.9 2.4 3.3 1. ]\n"," [6.6 2.9 4.6 1.3]\n"," [5.2 2.7 3.9 1.4]\n"," [5.  2.  3.5 1. ]\n"," [5.9 3.  4.2 1.5]\n"," [6.  2.2 4.  1. ]\n"," [6.1 2.9 4.7 1.4]\n"," [5.6 2.9 3.6 1.3]\n"," [6.7 3.1 4.4 1.4]\n"," [5.6 3.  4.5 1.5]\n"," [5.8 2.7 4.1 1. ]\n"," [6.2 2.2 4.5 1.5]\n"," [5.6 2.5 3.9 1.1]\n"," [5.9 3.2 4.8 1.8]\n"," [6.1 2.8 4.  1.3]\n"," [6.3 2.5 4.9 1.5]\n"," [6.1 2.8 4.7 1.2]\n"," [6.4 2.9 4.3 1.3]\n"," [6.6 3.  4.4 1.4]\n"," [6.8 2.8 4.8 1.4]\n"," [6.7 3.  5.  1.7]\n"," [6.  2.9 4.5 1.5]\n"," [5.7 2.6 3.5 1. ]\n"," [5.5 2.4 3.8 1.1]\n"," [5.5 2.4 3.7 1. ]\n"," [5.8 2.7 3.9 1.2]\n"," [6.  2.7 5.1 1.6]\n"," [5.4 3.  4.5 1.5]\n"," [6.  3.4 4.5 1.6]\n"," [6.7 3.1 4.7 1.5]\n"," [6.3 2.3 4.4 1.3]\n"," [5.6 3.  4.1 1.3]\n"," [5.5 2.5 4.  1.3]\n"," [5.5 2.6 4.4 1.2]\n"," [6.1 3.  4.6 1.4]\n"," [5.8 2.6 4.  1.2]\n"," [5.  2.3 3.3 1. ]\n"," [5.6 2.7 4.2 1.3]\n"," [5.7 3.  4.2 1.2]\n"," [5.7 2.9 4.2 1.3]\n"," [6.2 2.9 4.3 1.3]\n"," [5.1 2.5 3.  1.1]\n"," [5.7 2.8 4.1 1.3]\n"," [6.3 3.3 6.  2.5]\n"," [5.8 2.7 5.1 1.9]\n"," [7.1 3.  5.9 2.1]\n"," [6.3 2.9 5.6 1.8]\n"," [6.5 3.  5.8 2.2]\n"," [7.6 3.  6.6 2.1]\n"," [4.9 2.5 4.5 1.7]\n"," [7.3 2.9 6.3 1.8]\n"," [6.7 2.5 5.8 1.8]\n"," [7.2 3.6 6.1 2.5]\n"," [6.5 3.2 5.1 2. ]\n"," [6.4 2.7 5.3 1.9]\n"," [6.8 3.  5.5 2.1]\n"," [5.7 2.5 5.  2. ]\n"," [5.8 2.8 5.1 2.4]\n"," [6.4 3.2 5.3 2.3]\n"," [6.5 3.  5.5 1.8]\n"," [7.7 3.8 6.7 2.2]\n"," [7.7 2.6 6.9 2.3]\n"," [6.  2.2 5.  1.5]\n"," [6.9 3.2 5.7 2.3]\n"," [5.6 2.8 4.9 2. ]\n"," [7.7 2.8 6.7 2. ]\n"," [6.3 2.7 4.9 1.8]\n"," [6.7 3.3 5.7 2.1]\n"," [7.2 3.2 6.  1.8]\n"," [6.2 2.8 4.8 1.8]\n"," [6.1 3.  4.9 1.8]\n"," [6.4 2.8 5.6 2.1]\n"," [7.2 3.  5.8 1.6]\n"," [7.4 2.8 6.1 1.9]\n"," [7.9 3.8 6.4 2. ]\n"," [6.4 2.8 5.6 2.2]\n"," [6.3 2.8 5.1 1.5]\n"," [6.1 2.6 5.6 1.4]\n"," [7.7 3.  6.1 2.3]\n"," [6.3 3.4 5.6 2.4]\n"," [6.4 3.1 5.5 1.8]\n"," [6.  3.  4.8 1.8]\n"," [6.9 3.1 5.4 2.1]\n"," [6.7 3.1 5.6 2.4]\n"," [6.9 3.1 5.1 2.3]\n"," [5.8 2.7 5.1 1.9]\n"," [6.8 3.2 5.9 2.3]\n"," [6.7 3.3 5.7 2.5]\n"," [6.7 3.  5.2 2.3]\n"," [6.3 2.5 5.  1.9]\n"," [6.5 3.  5.2 2. ]\n"," [6.2 3.4 5.4 2.3]\n"," [5.9 3.  5.1 1.8]]\n"]}],"source":["print(data_input)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tuKivRDy8DkW","outputId":"e74d6266-a0b3-4f88-ce61-f0e4c748484d"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n"," 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n"," 2 2]\n"]}],"source":["print(data_output)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OUUBXS0o8DkY"},"outputs":[],"source":["#K-Folds cross-validator\n","#Provides train/test indices to split data in train/test sets. Split dataset into k consecutive folds\n","#(without shuffling by default). Each fold is then used once as a validation while the k - 1 remaining foldsform the training set.\n","\n","\n","from sklearn.model_selection import KFold\n","kf = KFold(n_splits =5, shuffle= True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rUa0qhfl8Dka","outputId":"e6b23b78-513e-40ba-9788-73f05e5a2f4e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Set              Test Set     \n","[  0   1   2   3   4   5   8   9  10  11  12  13  14  15  17  18  19  21\n","  23  24  26  27  28  31  32  33  34  35  36  37  38  39  40  41  42  43\n","  44  45  46  49  50  51  53  55  56  57  58  59  60  61  62  63  64  65\n","  66  67  68  69  70  71  72  73  74  76  77  78  79  80  81  82  83  84\n","  85  86  87  88  90  94  95  96  98  99 100 101 103 104 105 106 108 109\n"," 110 111 112 115 116 117 120 122 124 125 126 127 130 131 132 133 134 135\n"," 136 137 138 140 141 142 143 144 146 147 148 149] [  6   7  16  20  22  25  29  30  47  48  52  54  75  89  91  92  93  97\n"," 102 107 113 114 118 119 121 123 128 129 139 145]\n","[  0   2   3   5   6   7   8  10  11  12  13  14  15  16  18  20  21  22\n","  23  24  25  26  27  28  29  30  32  33  34  40  41  42  43  44  46  47\n","  48  49  50  52  53  54  55  56  57  58  59  60  62  64  65  66  67  68\n","  69  70  72  74  75  76  78  79  80  83  85  86  87  89  90  91  92  93\n","  95  96  97  98  99 101 102 103 104 106 107 108 109 110 111 112 113 114\n"," 115 116 117 118 119 120 121 123 124 126 127 128 129 131 134 135 136 137\n"," 138 139 140 141 142 143 144 145 146 147 148 149] [  1   4   9  17  19  31  35  36  37  38  39  45  51  61  63  71  73  77\n","  81  82  84  88  94 100 105 122 125 130 132 133]\n","[  0   1   2   3   4   5   6   7   8   9  10  11  12  15  16  17  19  20\n","  22  23  24  25  26  27  28  29  30  31  34  35  36  37  38  39  40  41\n","  42  43  44  45  46  47  48  50  51  52  53  54  55  57  59  60  61  62\n","  63  64  65  66  70  71  73  75  76  77  79  80  81  82  83  84  85  86\n","  87  88  89  91  92  93  94  95  96  97 100 102 104 105 106 107 108 109\n"," 112 113 114 117 118 119 121 122 123 125 126 127 128 129 130 131 132 133\n"," 134 137 138 139 141 143 144 145 146 147 148 149] [ 13  14  18  21  32  33  49  56  58  67  68  69  72  74  78  90  98  99\n"," 101 103 110 111 115 116 120 124 135 136 140 142]\n","[  1   2   4   6   7   8   9  10  12  13  14  15  16  17  18  19  20  21\n","  22  23  25  26  29  30  31  32  33  35  36  37  38  39  40  41  43  45\n","  47  48  49  51  52  53  54  55  56  57  58  60  61  63  67  68  69  71\n","  72  73  74  75  77  78  79  80  81  82  83  84  85  88  89  90  91  92\n","  93  94  95  96  97  98  99 100 101 102 103 104 105 107 108 109 110 111\n"," 112 113 114 115 116 118 119 120 121 122 123 124 125 127 128 129 130 131\n"," 132 133 134 135 136 137 138 139 140 142 144 145] [  0   3   5  11  24  27  28  34  42  44  46  50  59  62  64  65  66  70\n","  76  86  87 106 117 126 141 143 146 147 148 149]\n","[  0   1   3   4   5   6   7   9  11  13  14  16  17  18  19  20  21  22\n","  24  25  27  28  29  30  31  32  33  34  35  36  37  38  39  42  44  45\n","  46  47  48  49  50  51  52  54  56  58  59  61  62  63  64  65  66  67\n","  68  69  70  71  72  73  74  75  76  77  78  81  82  84  86  87  88  89\n","  90  91  92  93  94  97  98  99 100 101 102 103 105 106 107 110 111 113\n"," 114 115 116 117 118 119 120 121 122 123 124 125 126 128 129 130 132 133\n"," 135 136 139 140 141 142 143 145 146 147 148 149] [  2   8  10  12  15  23  26  40  41  43  53  55  57  60  79  80  83  85\n","  95  96 104 108 109 112 127 131 134 137 138 144]\n"]}],"source":["# this shows the different dataset that is split between test and train set\n","print('Train Set              Test Set     ')\n","for train_set,test_set in kf.split(data_input):\n","    print(train_set,test_set)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gsIVYlIB8Dkc"},"outputs":[],"source":["#Random forest is an ensemble of decision tree algorithms.It is an extension of bootstrap aggregation (bagging) of\n","#decision trees and can be used for classification and regression problems.\n","\n","from sklearn.ensemble import RandomForestClassifier\n","rf_class = RandomForestClassifier(n_estimators=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q29Wn4eB8Dkd","outputId":"22705927-6c22-4bd9-b982-b4b3a0a90e3a"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.93333333 0.93333333 1.         0.93333333 0.93333333 0.93333333\n"," 0.86666667 1.         1.         1.        ]\n"]}],"source":["#cross_val_score is used to perform the evaluation, taking the dataset and cross-validation configuration and returning\n","#a list of scores calculated for each fold.\n","\n","from sklearn.model_selection import cross_val_score\n","print(cross_val_score(rf_class, data_input, data_output, scoring='accuracy',cv=10))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bzDuODdW8Dkf","outputId":"e25c1d44-c9c8-47f2-f263-6f158ea555b5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy of Random Forests is: 96.66666666666666\n"]}],"source":["# The accuracy percentage\n","accuracy= cross_val_score(rf_class,data_input,data_output,scoring='accuracy',cv=10).mean()*100\n","print('Accuracy of Random Forests is:', accuracy)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"Ensemble_learning_ML_SOI.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}